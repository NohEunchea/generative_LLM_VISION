{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. LangChain 설치 및 업데이트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\ms211\\miniconda3\\envs\\torch_main\\lib\\site-packages (0.1.16)\n",
      "Requirement already satisfied: langchain-community in c:\\users\\ms211\\miniconda3\\envs\\torch_main\\lib\\site-packages (0.0.32)\n",
      "Collecting langchain-experimental\n",
      "  Obtaining dependency information for langchain-experimental from https://files.pythonhosted.org/packages/4d/4d/81725def89f72ac878be289929e8870fd5919744a8b603ad724f0263d61e/langchain_experimental-0.0.57-py3-none-any.whl.metadata\n",
      "  Downloading langchain_experimental-0.0.57-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: langchain-core in c:\\users\\ms211\\miniconda3\\envs\\torch_main\\lib\\site-packages (0.1.42)\n",
      "Requirement already satisfied: langchain-openai in c:\\users\\ms211\\miniconda3\\envs\\torch_main\\lib\\site-packages (0.1.3)\n",
      "Requirement already satisfied: langsmith in c:\\users\\ms211\\miniconda3\\envs\\torch_main\\lib\\site-packages (0.1.47)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\ms211\\miniconda3\\envs\\torch_main\\lib\\site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\ms211\\miniconda3\\envs\\torch_main\\lib\\site-packages (from langchain) (2.0.29)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\ms211\\miniconda3\\envs\\torch_main\\lib\\site-packages (from langchain) (3.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in c:\\users\\ms211\\miniconda3\\envs\\torch_main\\lib\\site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\ms211\\miniconda3\\envs\\torch_main\\lib\\site-packages (from langchain) (0.6.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\ms211\\miniconda3\\envs\\torch_main\\lib\\site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in c:\\users\\ms211\\miniconda3\\envs\\torch_main\\lib\\site-packages (from langchain) (0.0.1)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\ms211\\miniconda3\\envs\\torch_main\\lib\\site-packages (from langchain) (1.25.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\ms211\\miniconda3\\envs\\torch_main\\lib\\site-packages (from langchain) (2.6.4)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\ms211\\miniconda3\\envs\\torch_main\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\ms211\\miniconda3\\envs\\torch_main\\lib\\site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\ms211\\miniconda3\\envs\\torch_main\\lib\\site-packages (from langchain-core) (23.2)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.10.0 in c:\\users\\ms211\\miniconda3\\envs\\torch_main\\lib\\site-packages (from langchain-openai) (1.17.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.5.2 in c:\\users\\ms211\\miniconda3\\envs\\torch_main\\lib\\site-packages (from langchain-openai) (0.6.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\ms211\\miniconda3\\envs\\torch_main\\lib\\site-packages (from langsmith) (3.10.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\ms211\\miniconda3\\envs\\torch_main\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\ms211\\miniconda3\\envs\\torch_main\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\ms211\\miniconda3\\envs\\torch_main\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\ms211\\miniconda3\\envs\\torch_main\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\ms211\\miniconda3\\envs\\torch_main\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\ms211\\miniconda3\\envs\\torch_main\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\ms211\\miniconda3\\envs\\torch_main\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\ms211\\miniconda3\\envs\\torch_main\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\ms211\\miniconda3\\envs\\torch_main\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\ms211\\miniconda3\\envs\\torch_main\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\ms211\\miniconda3\\envs\\torch_main\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (0.27.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\ms211\\miniconda3\\envs\\torch_main\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\ms211\\miniconda3\\envs\\torch_main\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\ms211\\miniconda3\\envs\\torch_main\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (4.11.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\ms211\\miniconda3\\envs\\torch_main\\lib\\site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in c:\\users\\ms211\\miniconda3\\envs\\torch_main\\lib\\site-packages (from pydantic<3,>=1->langchain) (2.16.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ms211\\miniconda3\\envs\\torch_main\\lib\\site-packages (from requests<3,>=2->langchain) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ms211\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2->langchain) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ms211\\miniconda3\\envs\\torch_main\\lib\\site-packages (from requests<3,>=2->langchain) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ms211\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\ms211\\miniconda3\\envs\\torch_main\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\ms211\\miniconda3\\envs\\torch_main\\lib\\site-packages (from tiktoken<1,>=0.5.2->langchain-openai) (2023.12.25)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\ms211\\miniconda3\\envs\\torch_main\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.10.0->langchain-openai) (1.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\ms211\\miniconda3\\envs\\torch_main\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\ms211\\miniconda3\\envs\\torch_main\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (0.14.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ms211\\miniconda3\\envs\\torch_main\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.10.0->langchain-openai) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\ms211\\miniconda3\\envs\\torch_main\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Downloading langchain_experimental-0.0.57-py3-none-any.whl (193 kB)\n",
      "   ---------------------------------------- 0.0/193.4 kB ? eta -:--:--\n",
      "   -- ------------------------------------- 10.2/193.4 kB ? eta -:--:--\n",
      "   -------- ------------------------------ 41.0/193.4 kB 653.6 kB/s eta 0:00:01\n",
      "   ------------------ -------------------- 92.2/193.4 kB 751.6 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 184.3/193.4 kB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 193.4/193.4 kB 1.1 MB/s eta 0:00:00\n",
      "Installing collected packages: langchain-experimental\n",
      "Successfully installed langchain-experimental-0.0.57\n"
     ]
    }
   ],
   "source": [
    "# !pip install -U langchain langchain-community langchain-experimental langchain-core langchain-openai langsmith"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. API 키 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os \n",
    "\n",
    "# API KEY 가져오기\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 간단한 응답 받아보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI 답변 : 축구 경기는 각 팀마다 11명의 선수로 진행됩니다. 따라서 두 팀을 합하면 총 22명의 선수가 필드에서 경기를 합니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 객체 생성\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.1,  # 창의성 (0.0 ~ 2.0)\n",
    "    max_tokens=2048,  # 최대 토큰수\n",
    "    model_name=\"gpt-4-turbo\",  # 모델명\n",
    ")\n",
    "\n",
    "# 질문내용\n",
    "question = \"축구는 몇 명이서 경기하나요?\"\n",
    "answer = llm.invoke(question)\n",
    "\n",
    "# 답변 내용\n",
    "print(f\"AI 답변 : {answer.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 템플릿 형식 구성해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['sports'] template='{sports}는 몇 명이서 경기하나요?'\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# 질문 양식 설정 - 템플릿 설정\n",
    "template = \"{sports}는 몇 명이서 경기하나요?\"\n",
    "\n",
    "# 프롬프트 템플릿 구성하기\n",
    "prompt = PromptTemplate.from_template(template=template)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-1. 체인 구성해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "# 프롬프트와 llm 모델 연결한 체인 구성\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='야구 경기는 각 팀마다 9명의 선수가 필드에 나서서 진행합니다. 따라서 두 팀을 합쳐 총 18명의 선수가 경기에 참여합니다.', response_metadata={'token_usage': {'completion_tokens': 64, 'prompt_tokens': 22, 'total_tokens': 86}, 'model_name': 'gpt-4-turbo', 'system_fingerprint': 'fp_76f018034d', 'finish_reason': 'stop', 'logprobs': None}, id='run-c1ab17ca-e4d3-4fd0-8b55-50e3618f9d8f-0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.invoke({\"sports\": \"야구\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': '농구 경기는 통상적으로 각 팀마다 5명의 선수가 코트 위에서 경기를 합니다. 따라서 두 팀을 합쳐 총 10명의 선수가 경기에 참여합니다.'}\n",
      "{'text': '배구 경기는 팀마다 6명의 선수로 구성되어 진행됩니다. 따라서 경기장에는 두 팀을 합쳐 총 12명의 선수가 경기에 참여합니다.'}\n",
      "{'text': '씨름 경기는 보통 두 명의 선수가 서로 대결하는 방식으로 진행됩니다. 각 선수는 상대방을 힘과 기술을 사용하여 지면에 넘어뜨리거나 경기장 밖으로 밀어내는 것을 목표로 합니다.'}\n"
     ]
    }
   ],
   "source": [
    "# 여러 개의 값을 key-value의 값으로 질문하기\n",
    "input_list = [{\"sports\": \"농구\"}, {\"sports\": \"배구\"}, {\"sports\": \"씨름\"}]\n",
    "\n",
    "response = llm_chain.apply(input_list)\n",
    "for message in response:\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-2. 여러 변수 지정한 템플릿 구성해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['stock1', 'stock2'], template='{stock1} 와 {stock2} 중에 어떤 주식이 더 유망해 보여?')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 질문 템플릿 형식 정의\n",
    "template = \"{stock1} 와 {stock2} 중에 어떤 주식이 더 유망해 보여?\"\n",
    "\n",
    "# 템플릿 완성\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'stock1': 'nVIDIA', 'stock2': 'Apple', 'text': '두 회사 모두 각자의 분야에서 매우 강력한 위치를 차지하고 있으며, 투자의 유망성은 여러 요소에 따라 달라질 수 있습니다. NVIDIA와 Apple 모두 기술 산업에서 중요한 역할을 하고 있지만, 각각의 회사가 집중하고 있는 분야와 시장 전망은 다소 다릅니다.\\n\\n1. **NVIDIA**:\\n   - **분야**: 주로 그래픽 처리 장치(GPU) 제조에 초점을 맞추고 있으며, AI, 데이터 센터, 자동차 및 게이밍 산업에서도 중요한 역할을 하고 있습니다.\\n   - **장점**: AI와 머신러닝 분야에서의 강력한 입지, 고성능 컴퓨팅과 데이터 센터 시장에서의 성장 가능성.\\n   - **위험 요소**: 경쟁이 치열해지고 있으며, 특히 AMD와의 경쟁, 공급망 문제 등이 영향을 미칠 수 있습니다.\\n\\n2. **Apple**:\\n   - **분야**: 소비자 전자제품, 컴퓨터 소프트웨어, 온라인 서비스 등을 제공하며, 특히 iPhone, iPad, Mac, Apple Watch 등의 제품으로 유명합니다.\\n   - **장점**: 강력한 브랜드 인지도, 충성도 높은 고객 기반, 다양한 제품 포트폴리오와 서비스.\\n   - **위험 요소**: 시장 포화, 기술 혁신의 압박, 글로벌 공급망 문제 등이 도전 요소로 작용할 수 있습니다.\\n\\n**투자 결정 시 고려할 점**:\\n- **시장 동향**: 기술 산업의 최신 동향과 미래 전망을 파악하는 것이 중요합니다.\\n- **개인의 투자 목표와 위험 감수 능력**: 장기적인 성장을 추구할 것인지, 단기 수익을 목표로 할 것인지에 따라 선택이 달라질 수 있습니다.\\n- **다양화**: 한 회사에만 집중 투자하기보다는 포트폴리오를 다양화하여 위험을 분산시키는 전략도 고려해 볼 수 있습니다.\\n\\n최종적으로, 개인의 투자 성향과 시장 상황을 종합적으로 고려하여 결정하는 것이 중요합니다. 또한, 전문가의 조언을 구하거나 추가적인 시장 분석을 통해 보다 정보에 기반한 결정을 내리는 것이 좋습니다.'}\n"
     ]
    }
   ],
   "source": [
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "print(llm_chain.invoke({\"stock1\": \"nVIDIA\", \"stock2\": \"Apple\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 스트리밍 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "# 객체 생성\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.1,  # 창의성 (0.0 ~ 2.0)\n",
    "    max_tokens=2048,  # 최대 토큰수\n",
    "    model_name=\"gpt-4-turbo\",  # 모델명\n",
    "    streaming=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능(AI)은 기계가 인간처럼 학습하고 문제를 해결하는 기술입니다. 기본적으로 데이터를 분석하고 패턴을 인식하여 예측 및 결정을 내리는 알고리즘을 사용합니다. 현재 AI는 의료 분야에서 질병 진단, 자율주행차에서의 운전 지원, 금융에서의 거래 감지, 제조업에서의 공정 최적화, 고객 서비스에서의 챗봇 등 다양한 분야에 활용되고 있습니다. 이러한 기술은 효율성을 높이고, 비용을 절감하며, 새로운 기회를 창출하는 데 기여하고 있습니다."
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "question = \"인공지능의 기본 원리와 현재 인공지능 기술이 어떻게 활용되고 있는지에 대해 300자 내외로 최대한 상세히 알려줘\"\n",
    "prompt = ChatPromptTemplate.from_template(question)\n",
    "chain = prompt | llm\n",
    "\n",
    "for s in chain.stream({\"question\": question}):\n",
    "    # 스트림에서 받은 데이터의 내용을 출력합니다. 줄바꿈 없이 이어서 출력하고, 버퍼를 즉시 비웁니다.\n",
    "    print(s.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. StrOutputParser 구성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 구성 양식 - model, prompt, output_parser\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model=\"gpt-4-turbo\",\n",
    "    max_tokens=2048,\n",
    "    temperature=0.1,\n",
    ")\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "축구는 전 세계에서 가장 인기 있는 스포츠 중 하나로, 두 팀이 각각의 골대를 향해 공을 차서 득점을 하는 게임입니다. \n",
      "\n",
      "- 경기 방식:\n",
      "축구 경기는 주로 잔디밭 위의 직사각형 필드에서 진행됩니다. 경기는 전반과 후반, 각각 45분씩 총 90분 동안 진행됩니다. 경기의 목표는 상대 팀의 골대에 공을 넣어 득점을 하는 것이며, 경기 시간이 끝났을 때 더 많은 골을 넣은 팀이 승리합니다. 경기 중에는 주심과 두 명의 부심이 규칙을 감독하며, 필요에 따라 추가 시간이 부여될 수 있습니다.\n",
      "\n",
      "- 선수 수:\n",
      "각 팀은 11명의 선수로 구성됩니다. 이 중 한 명은 골키퍼로, 골대를 지키는 역할을 합니다. 나머지 10명은 수비수, 미드필더, 공격수 등 다양한 포지션에서 경기를 펼칩니다. 경기 중에는 교체 선수를 일정 횟수만큼 투입할 수 있으며, 최근 규칙에 따라 대부분의 공식 경기에서는 최대 5명까지 교체가 가능합니다.\n",
      "\n",
      "- 기타 정보:\n",
      "축구는 국제축구연맹(FIFA)에 의해 규제되며, 4년마다 월드컵이 개최되어 전 세계의 국가들이 참가합니다. 이 외에도 각 대륙별로 자체 대회들이 있으며, 클럽 레벨에서는 유럽의 UEFA 챔피언스 리그, 남미의 코파 리베르타도레스 등 다양한 대회가 있습니다. 축구는 단순히 경기의 승패를 넘어서, 많은 사람들에게 열정과 국가적 자긍심을 불러일으키는 스포츠입니다.\n"
     ]
    }
   ],
   "source": [
    "# 주어진 스포츠에 대하여 플레이어 수를 묻는 프롬프트 템플릿을 생성합니다.\n",
    "template = \"\"\"\n",
    "당신은 스포츠 전문가입니다. 사용자의 질문에 정확하고, 친절하게 답변해 주세요. [내용]에 맞게 답변해주세요\n",
    "답변은 항상 한글로 작성해 주세요.\n",
    "\n",
    "질문:\n",
    "{question}\n",
    "\n",
    "내용:\n",
    "- 경기 방식:\n",
    "- 선수 수:\n",
    "- 기타 정보:\n",
    "\"\"\"\n",
    "\n",
    "# 프롬프트 템플릿에서 프롬프트 생성\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# 프롬프트, 모델, 출력 파서를 연결하여 처리 체인을 구성합니다.\n",
    "chain = prompt | model | output_parser\n",
    "\n",
    "# 완성된 Chain 을 이용하여 question 을 축구에 대해서 설명해주세요 바꾸었습니다.\n",
    "result = chain.invoke({\"question\": \"축구에 대해서 설명해주세요\"})\n",
    "print(result) # 결과가 string 값으로 출력됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. 비동기 방식으로 처리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "축구는 전 세계적으로 가장 인기 있는 스포츠 중 하나로, 두 팀이 각각의 골대를 향해 공을 차서 득점을 하는 게임입니다. \n",
      "\n",
      "- 경기 방식:\n",
      "축구 경기는 주로 잔디밭 위의 직사각형 필드에서 진행되며, 각 팀은 한 골키퍼를 포함해 11명의 선수가 필드에 출전합니다. 경기는 전반과 후반, 각각 45분씩 총 90분 동안 진행됩니다. 경기의 목표는 상대 팀의 골대에 공을 넣어 득점을 하는 것이며, 경기 시간이 끝났을 때 더 많은 골을 넣은 팀이 승리합니다. 경기 중에는 오프사이드, 파울, 핸드볼 등의 규칙을 준수해야 하며, 위반 시 자유킥, 페널티킥 또는 경고(옐로 카드)와 퇴장(레드 카드) 등의 패널티가 주어질 수 있습니다.\n",
      "\n",
      "- 선수 수:\n",
      "각 축구 팀은 골키퍼 1명을 포함해 총 11명의 선수로 구성됩니다. 경기 중 선수 교체도 가능한데, 대부분의 공식 경기에서는 최대 3명의 선수를 교체할 수 있습니다. \n",
      "\n",
      "- 기타 정보:\n",
      "축구는 FIFA(국제축구연맹)에 의해 규제되며, 4년마다 월드컵이 개최되어 전 세계의 국가들이 참가해 그들의 기량을 겨룹니다. 축구는 단순히 체력과 기술뿐만 아니라 전략과 팀워크가 매우 중요한 스포츠입니다. 또한, 각 나라마다 자체 리그 시스템이 있고, 유럽의 경우 UEFA 챔피언스 리그와 같은 대륙간 대회도 매우 인기가 있습니다."
     ]
    }
   ],
   "source": [
    "async for s in chain.astream({\"question\": \"축구에 대해서 설명해주세요\"}):\n",
    "    # 메시지 내용을 출력합니다. 줄바꿈 없이 바로 출력하고 버퍼를 비웁니다.\n",
    "    print(s, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. 시스템 템플릿, 휴먼 템플릿으로 구성해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['language', 'text'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['language'], template='당신은 {language} 선생님입니다. {language}로 답변해주세요')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['text'], template='{text}'))])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# System 메세지 구성\n",
    "system_message = \"당신은 {language} 선생님입니다. {language}로 답변해주세요\"\n",
    "system_prompt = SystemMessagePromptTemplate.from_template(system_message)\n",
    "\n",
    "# Human 메세지 구성\n",
    "human_message = \"{text}\"\n",
    "human_prompt = HumanMessagePromptTemplate.from_template(human_message)\n",
    "\n",
    "# 최종 프롬프트 구성\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_prompt, human_prompt])\n",
    "chat_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(\n",
    "    model=\"gpt-4-turbo\",\n",
    "    max_tokens=2048,\n",
    "    temperature=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of South Korea is Seoul.\n"
     ]
    }
   ],
   "source": [
    "chain = chat_prompt | model | output_parser\n",
    "\n",
    "# 완성된 Chain 을 이용하여 주어진 텍스트를 영어로 응답을 해달라는 요청을 합니다.\n",
    "result = chain.invoke({\"language\": \"영어\", \"text\": \"대한민국의 수도는 어디인가요?\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
